# **ğŸ‹ï¸ Sword ML Engineer Test**
> **End-to-End Data Transformation and AI Message Generation Pipeline**

## **ğŸ“Œ Index**
1. [Project Overview](#project-overview)
2. [Repository Structure](#repository-structure)
3. [Branching Strategy](#branching-strategy)
4. [Setup Instructions](#setup-instructions)
5. [Data Transformation](#data-transformation)
6. [AI Message Generation](#ai-message-generation)
7. [Running the Pipeline](#running-the-pipeline)
8. [Testing](#testing)
9. [Future Improvements](#future-improvements)

---

## **ğŸ“Œ Project Overview**
This project automates **patient follow-up messaging** based on **session performance data** by leveraging:
- **Data Transformation:** Aggregating raw session data (`exercise_results.parquet`) into a structured format using **DuckDB & SQL**.
- **AI Message Generation:** Generating **personalized messages** for patients using **OpenAI GPT-4**.

The goal is to:
âœ”ï¸ **Enable data-driven decision-making** for PTs  
âœ”ï¸ **Ensure consistent & engaging** patient communication  
âœ”ï¸ **Reduce manual workload** by automating messaging  

---

## **ğŸ‘¤ Repository Structure**
```
ml-engineer-test/
â”‚â”€â”€ message/                        # Core application logic
â”‚   â”œâ”€â”€ data.py                     # Data transformation logic
â”‚   â”œâ”€â”€ main.py                     # Entry point for commands (transform, get_message)
â”‚   â”œâ”€â”€ model.py                    # OpenAI model integration
â”‚   â”œâ”€â”€ prompt_manager.py           # Manages AI prompt templates
|   â”œâ”€â”€ config.py    
â”‚â”€â”€ prompts/                        # AI message templates
â”‚   â”œâ”€â”€ system_prompt.txt
â”‚   â”œâ”€â”€ user_prompt.txt
â”‚   â”œâ”€â”€ scenario_ok.txt
â”‚   â”œâ”€â”€ scenario_nok.txt
â”‚â”€â”€ data/                           # Raw & transformed datasets
â”‚   â”œâ”€â”€ exercise_results.parquet    # Input
â”‚   â”œâ”€â”€ features_expected.parquet   # Expected Output
â”‚   â”œâ”€â”€ features.parquet            # Output
â”‚â”€â”€ notebooks/                      # Jupyter Notebooks for debugging
â”‚   â”œâ”€â”€ data-transformation.ipynb   # Testing for Question 1
â”‚   â”œâ”€â”€ starter.ipynb               # Testing for Question 2
â”‚â”€â”€ queries/                        # SQL queries for DuckDB
â”‚â”€â”€ tests/                          # Unit tests for queries
â”‚   â”œâ”€â”€ test_transformations.py 
â”‚â”€â”€ Makefile                        # Command-line automation
â”‚â”€â”€ requirements.txt                # Dependencies
â”‚â”€â”€ README.md                       # Project documentation
```

---

## **ğŸŒ± Branching Strategy**
This project follows a **feature-branch workflow**:

| Branch                          | Purpose                                   |
|---------------------------------|-------------------------------------------|
| **main**                        | Stable production-ready code              |
| **feature/data-transformation** | Question 1                                |
| **feature/ai-generated-message**| Question 2                                |

Merging was done via **separate PRs per feature branch** to keep changes modular and reviewable, and to simmulate real productization scenario.

---

## **âš™ï¸ Setup Instructions**
### **1ï¸âƒ£ Clone the repository**
```bash
git clone <your-repo-url>
cd ml-engineer-test
```

### **2ï¸âƒ£ Create & Activate Virtual Environment**
```bash
make venv  # Automatically creates and activates a virtual environment
source venv/bin/activate 
```

### **3ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **4ï¸âƒ£ Setup Environment Variables**
Create a `.env` file in the project root:
```bash
touch .env
```
Add your **OpenAI API Key** inside `.env`:
```
OPENAI_API_KEY=your-openai-key-here
```